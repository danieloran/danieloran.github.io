---
layout: post
title: "AI finds its voice: Collaborating with conversational computers"
date: 2025-02-11
image: "/assets/images/talk.jpg"
---
![Man in front of laptop screen with text that says, "Let's talk."](/assets/images/letstalk.jpg)

Since the launch of OpenAI’s ChatGPT, I’ve gotten used to being amazed by AI chatbots.

But I hadn’t anticipated how conversing out loud would transform the experience so fundamentally. I feel like I’m having a discussion with the AI in a way that typing back and forth can’t match.

Suddenly, it seems reasonable to suggest that voice AI will change how we interact with computers.

Until recently, computer voices seemed off, with weird intonations that made them sound robotic, not human.

In contrast, the latest voices of ChatGPT and Google’s Gemini Live sound thoroughly human. And their AI also excels at listening: the speech recognition is remarkably accurate and quick, so the apps can reliably make sense of your spoken words — and usually respond without a noticeable delay.

Being able to discuss with the AI what you see on the screen — in the casual way that you might talk with a friend — would certainly make computers a lot easier to use. But more important, it might change what we use them for.

A conversational computer might not only help you do things — for example, figure out how to use a specific software feature — but also help you think, serving as a brainstorming partner, teacher, or even confidant, depending upon the situation.

So far, though, creating collaborative, real-time experiences hasn’t been the primary focus of recent innovation in AI. Instead, many current uses of AI involve handing off tasks like drafting an email or writing computer code.

This might be called the delegation model of AI: it works *for* us, like an eager-to-please subordinate. You give instructions, then you can walk away — like the “batch mode” of old mainframe computers, which processed stacks of punch cards while you went for coffee.

But some of the best-known early speculation about the future of computing — from Vannevar Bush’s “[As We May Think](https://en.wikipedia.org/wiki/As_We_May_Think)” in 1945 to Douglas Engelbart’s “[Augmenting Human Intellect](https://www.taylorfrancis.com/chapters/oa-edit/10.4324/9781003230762-3/augmenting-human-intellect-douglas-engelbart)” in 1962 — focused instead on collaboration: imagining how smart machines might work *with* us to enhance our abilities.

They thought that we’d interact directly with machine intelligence, instead of just delegating and walking away. Interacting right now instead of getting results later makes the experience very different.

In 1987, Apple released a speculative (and prophetic) video, “[Knowledge Navigator](https://www.youtube.com/watch?v=-jiBLQyUi38),” with a similarly collaborative conception of AI. A college professor speaks with an AI assistant while using a touchscreen computer. The interaction feels like a give-and-take with a graduate student.

We’re heading toward that kind of collaborative voice AI, but it’s still early days. As yet, no real-world product comes close to the fictional Knowledge Navigator. It’s probably going to take a while, and if history is any guide, the breakthroughs may not come from today’s dominant players.

In the early ’90s, as the graphical user interface became increasingly popular, software leaders like Lotus and WordPerfect withered as they struggled to make the leap. And after the Apple iPhone changed the interaction paradigm in 2007, phone giants like BlackBerry and Nokia tanked. Conversational computers may turn out to be a similar watershed.

“The best way to predict the future is to invent it,” said Alan Kay, the pioneering computer scientist. We’re now living through a period of intense invention in voice AI that will shape the future of computing for decades to come.
