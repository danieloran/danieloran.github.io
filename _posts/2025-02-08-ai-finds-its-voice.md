---
layout: post
title: "AI finds its voice: Collaborating with conversational computers"
date: 2025-02-08
---
Since the launch of ChatGPT, I’ve gotten used to being amazed by AI chatbots. But I hadn’t anticipated how conversing out loud would transform the experience so fundamentally. I feel like I’m having a discussion with the AI in a way that typing back and forth can’t match.

Until recently, computer voices seemed off, with weird intonations that made them sound robotic, not human. In contrast, the new voices of OpenAI’s ChatGPT and Google’s Gemini Live sound thoroughly human. And their AI also excels at listening: the speech recognition is remarkably accurate and quick, so they can reliably make sense of your spoken words — and respond without a noticeable delay.

Suddenly, it seems reasonable to suggest that voice AI will change how we interact with computers.

For the last 30 years, the primary way that we’ve controlled computers has been with a mouse or a finger — what computer scientists call direct manipulation.

Voice AI would make computers a lot easier to use. You could discuss with the AI what both of you see on the screen.

Creating collaborative AI experiences, though, hasn’t been the focus of most innovation so far. Instead, AI has been generally conceived of as an “agent” to which you can hand off tasks like drafting a letter, writing computer code, or even shopping online.

This might be called the delegation model of AI: it works *for* us, like an eager-to-please subordinate. You give instructions, then you can walk away — like the “batch mode” of old mainframe computers, which processed stacks of punch cards while you went for coffee.

But some of the best-known early speculations about the future of computing — from Vannevar Bush’s “[As We May Think](https://en.wikipedia.org/wiki/As_We_May_Think)” in 1945 to Douglas Engelbart’s “[Augmenting Human Intellect](https://www.taylorfrancis.com/chapters/oa-edit/10.4324/9781003230762-3/augmenting-human-intellect-douglas-engelbart)” in 1962 — focused instead on collaboration: imagining how smart machines might work *with* us to enhance our abilities.

They thought that we’d interact directly with machine intelligence, instead of just delegating and walking away. Interacting right now instead of getting results later — in fancier terms, synchronously, rather than asynchronously — makes the experience very different.

In 1987, Apple released a speculative (and prophetic) video, “[Knowledge Navigator](https://www.youtube.com/watch?v=-jiBLQyUi38),” with a similarly collaborative conception of AI. A college professor speaks with an AI assistant while using a touchscreen computer. The interaction feels like a give-and-take with a graduate student.

We’re heading toward that kind of collaborative voice AI, but it’s still early days. As yet, no real-world product comes close to the fictional Knowledge Navigator. It’s probably going to take a while, and the breakthroughs may not come from today’s dominant players, if history is any guide.

In the early ’90s, as the graphical user interface became increasingly popular, software leaders like Lotus and WordPerfect withered as they struggled to make the leap. And after the Apple iPhone changed the interaction paradigm in 2007, phone giants like BlackBerry and Nokia tanked. Voice AI user interfaces may turn out to be a similar watershed.

“The best way to predict the future is to invent it,” said Alan Kay, the pioneering computer scientist. We’re now living through a period of intense invention in voice AI that will shape the future of computing for decades to come.
